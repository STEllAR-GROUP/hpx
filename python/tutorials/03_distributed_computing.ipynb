{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Distributed Computing with HPXPy\n",
    "\n",
    "HPXPy supports distributed computing across multiple processes (localities). This tutorial covers:\n",
    "\n",
    "- Collective operations (all_reduce, broadcast, gather, scatter)\n",
    "- Distributed arrays\n",
    "- Distribution policies\n",
    "- Multi-locality concepts\n",
    "\n",
    "**Note**: In single-locality mode (one process), collective operations return sensible defaults. The full power of these features is realized when running across multiple localities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpxpy as hpx\n",
    "import numpy as np\n",
    "\n",
    "# Initialize HPX runtime\n",
    "hpx.init()\n",
    "\n",
    "print(f\"HPXPy version: {hpx.__version__}\")\n",
    "print(f\"Number of localities: {hpx.num_localities()}\")\n",
    "print(f\"Current locality ID: {hpx.locality_id()}\")\n",
    "print(f\"Number of threads: {hpx.num_threads()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectives-header",
   "metadata": {},
   "source": [
    "## 1. Collective Operations\n",
    "\n",
    "Collective operations are communication patterns that involve all localities in a distributed computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allreduce-header",
   "metadata": {},
   "source": [
    "### All-Reduce\n",
    "\n",
    "Combines values from all localities and distributes the result to everyone.\n",
    "\n",
    "```\n",
    "Locality 0: [1, 2, 3]  ─┐\n",
    "Locality 1: [4, 5, 6]  ─┼─► all_reduce(sum) ─► [5, 7, 9] (to all)\n",
    "Locality 2: [0, 0, 0]  ─┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allreduce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local data\n",
    "local_data = hpx.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "print(\"Local data:\", local_data.to_numpy())\n",
    "\n",
    "# All-reduce with different operations\n",
    "print(\"\\nAll-reduce operations:\")\n",
    "print(\"  sum:\", hpx.all_reduce(local_data, op='sum').to_numpy())\n",
    "print(\"  prod:\", hpx.all_reduce(local_data, op='prod').to_numpy())\n",
    "print(\"  min:\", hpx.all_reduce(local_data, op='min').to_numpy())\n",
    "print(\"  max:\", hpx.all_reduce(local_data, op='max').to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allreduce-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: Global statistics\n",
    "# In a distributed setting, each locality would have different local_stats\n",
    "local_stats = hpx.array([100.0, 50.0, 200.0])  # [count, min, max]\n",
    "\n",
    "# Combine across localities\n",
    "global_count = hpx.all_reduce(hpx.array([local_stats[0]]), op='sum')\n",
    "global_min = hpx.all_reduce(hpx.array([local_stats[1]]), op='min')\n",
    "global_max = hpx.all_reduce(hpx.array([local_stats[2]]), op='max')\n",
    "\n",
    "print(\"Global statistics:\")\n",
    "print(f\"  Total count: {global_count.to_numpy()[0]}\")\n",
    "print(f\"  Global min: {global_min.to_numpy()[0]}\")\n",
    "print(f\"  Global max: {global_max.to_numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadcast-header",
   "metadata": {},
   "source": [
    "### Broadcast\n",
    "\n",
    "Sends data from one locality (root) to all other localities.\n",
    "\n",
    "```\n",
    "Locality 0: [1, 2, 3]  ─── broadcast(root=0) ───► [1, 2, 3] (to all)\n",
    "Locality 1: [?, ?, ?]  ─────────────────────────► [1, 2, 3]\n",
    "Locality 2: [?, ?, ?]  ─────────────────────────► [1, 2, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root locality has the data to share\n",
    "if hpx.locality_id() == 0:\n",
    "    config_data = hpx.array([3.14159, 2.71828, 1.41421])\n",
    "else:\n",
    "    config_data = hpx.zeros(3)  # Placeholder on other localities\n",
    "\n",
    "print(\"Before broadcast:\", config_data.to_numpy())\n",
    "\n",
    "# Broadcast from root=0\n",
    "shared_config = hpx.broadcast(config_data, root=0)\n",
    "print(\"After broadcast:\", shared_config.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gather-header",
   "metadata": {},
   "source": [
    "### Gather\n",
    "\n",
    "Collects data from all localities to a single root locality.\n",
    "\n",
    "```\n",
    "Locality 0: [1, 2]  ─┐\n",
    "Locality 1: [3, 4]  ─┼─► gather(root=0) ─► [[1,2], [3,4], [5,6]] (on root)\n",
    "Locality 2: [5, 6]  ─┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each locality contributes its data\n",
    "my_contribution = hpx.array([hpx.locality_id() * 10 + i for i in range(3)])\n",
    "print(f\"My contribution (locality {hpx.locality_id()}):\", my_contribution.to_numpy())\n",
    "\n",
    "# Gather to root\n",
    "all_data = hpx.gather(my_contribution, root=0)\n",
    "\n",
    "if hpx.locality_id() == 0:\n",
    "    print(f\"\\nGathered {len(all_data)} arrays at root:\")\n",
    "    for i, arr in enumerate(all_data):\n",
    "        print(f\"  From locality {i}: {arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scatter-header",
   "metadata": {},
   "source": [
    "### Scatter\n",
    "\n",
    "Distributes portions of data from root to all localities.\n",
    "\n",
    "```\n",
    "Locality 0: [1,2,3,4,5,6] ─► scatter(root=0) ─► [1,2] (to loc 0)\n",
    "                                             ─► [3,4] (to loc 1)\n",
    "                                             ─► [5,6] (to loc 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scatter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root has all the data\n",
    "if hpx.locality_id() == 0:\n",
    "    full_data = hpx.arange(12)  # [0, 1, 2, ..., 11]\n",
    "    print(\"Full data on root:\", full_data.to_numpy())\n",
    "else:\n",
    "    full_data = hpx.zeros(12)  # Placeholder\n",
    "\n",
    "# Scatter distributes chunks\n",
    "my_chunk = hpx.scatter(full_data, root=0)\n",
    "print(f\"My chunk (locality {hpx.locality_id()}):\", my_chunk.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "barrier-header",
   "metadata": {},
   "source": [
    "### Barrier\n",
    "\n",
    "Synchronizes all localities - everyone waits until all reach the barrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Locality {hpx.locality_id()} starting computation...\")\n",
    "\n",
    "# Simulate some work\n",
    "result = hpx.sum(hpx.arange(1000000))\n",
    "\n",
    "# Synchronize before continuing\n",
    "hpx.barrier(\"computation_done\")\n",
    "\n",
    "print(f\"Locality {hpx.locality_id()} passed barrier with result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectives-module-header",
   "metadata": {},
   "source": [
    "### Collectives Module\n",
    "\n",
    "Additional locality functions are available in the `hpx.collectives` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectives-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access locality information via collectives module\n",
    "print(\"Via hpx.collectives module:\")\n",
    "print(f\"  Number of localities: {hpx.collectives.get_num_localities()}\")\n",
    "print(f\"  Current locality ID: {hpx.collectives.get_locality_id()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-arrays-header",
   "metadata": {},
   "source": [
    "## 2. Distributed Arrays\n",
    "\n",
    "Distributed arrays span multiple localities with automatic data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distributed arrays\n",
    "d_zeros = hpx.distributed_zeros([100])\n",
    "d_ones = hpx.distributed_ones([50, 2])\n",
    "d_full = hpx.distributed_full([20], 3.14)\n",
    "\n",
    "print(\"Distributed zeros:\")\n",
    "print(f\"  Shape: {d_zeros.shape}\")\n",
    "print(f\"  Size: {d_zeros.size}\")\n",
    "print(f\"  First 10: {d_zeros.to_numpy()[:10]}\")\n",
    "\n",
    "print(\"\\nDistributed ones:\")\n",
    "print(f\"  Shape: {d_ones.shape}\")\n",
    "print(f\"  First row: {d_ones.to_numpy()[0]}\")\n",
    "\n",
    "print(\"\\nDistributed full (3.14):\")\n",
    "print(f\"  Values: {d_full.to_numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "from-numpy-distributed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distributed array from NumPy\n",
    "np_data = np.linspace(0, 10, 20)\n",
    "d_arr = hpx.distributed_from_numpy(np_data)\n",
    "\n",
    "print(\"From NumPy:\")\n",
    "print(f\"  Original: {np_data}\")\n",
    "print(f\"  Distributed: {d_arr.to_numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distribution-policies-header",
   "metadata": {},
   "source": [
    "### Distribution Policies\n",
    "\n",
    "Control how data is partitioned across localities:\n",
    "\n",
    "- **none**: No distribution (local array)\n",
    "- **block**: Contiguous chunks to each locality\n",
    "- **cyclic**: Round-robin distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distribution-policies",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available distribution policies\n",
    "print(\"Distribution Policies:\")\n",
    "print(f\"  None:  {hpx.DistributionPolicy.none}\")\n",
    "print(f\"  Block: {hpx.DistributionPolicy.block}\")\n",
    "print(f\"  Cyclic: {hpx.DistributionPolicy.cyclic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-with-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays with different distribution policies\n",
    "arr_none = hpx.distributed_zeros([100])  # Default: no distribution\n",
    "arr_block = hpx.distributed_zeros([100], distribution='block')\n",
    "arr_cyclic = hpx.distributed_zeros([100], distribution='cyclic')\n",
    "\n",
    "print(\"Distribution policies:\")\n",
    "print(f\"  None policy:   {arr_none.policy}\")\n",
    "print(f\"  Block policy:  {arr_block.policy}\")\n",
    "print(f\"  Cyclic policy: {arr_cyclic.policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-properties-header",
   "metadata": {},
   "source": [
    "### Distributed Array Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-properties",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distributed array\n",
    "darr = hpx.distributed_ones([1000], distribution='block')\n",
    "\n",
    "print(\"Distributed Array Properties:\")\n",
    "print(f\"  Shape: {darr.shape}\")\n",
    "print(f\"  Size: {darr.size}\")\n",
    "print(f\"  Dimensions: {darr.ndim}\")\n",
    "print(f\"  Policy: {darr.policy}\")\n",
    "print(f\"  Num partitions: {darr.num_partitions}\")\n",
    "print(f\"  Locality ID: {darr.locality_id}\")\n",
    "print(f\"  Is distributed: {darr.is_distributed()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distribution-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed distribution information\n",
    "info = darr.get_distribution_info()\n",
    "\n",
    "print(\"Distribution Info:\")\n",
    "print(f\"  Policy: {info.policy}\")\n",
    "print(f\"  Num partitions: {info.num_partitions}\")\n",
    "print(f\"  Chunk size: {info.chunk_size}\")\n",
    "print(f\"  Locality ID: {info.locality_id}\")\n",
    "print(f\"  Is distributed: {info.is_distributed()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-methods-header",
   "metadata": {},
   "source": [
    "### Distributed Array Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-methods",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with a value\n",
    "darr = hpx.distributed_zeros([10], distribution='block')\n",
    "print(\"Before fill:\", darr.to_numpy())\n",
    "\n",
    "darr.fill(42.0)\n",
    "print(\"After fill(42):\", darr.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "to-numpy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy (gathers all data if distributed)\n",
    "darr = hpx.distributed_full([5], 7.0, distribution='block')\n",
    "\n",
    "np_arr = darr.to_numpy()\n",
    "print(f\"Type: {type(np_arr)}\")\n",
    "print(f\"Values: {np_arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-repr-header",
   "metadata": {},
   "source": [
    "### String Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-repr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the string representation\n",
    "darr_none = hpx.distributed_zeros([100])\n",
    "darr_block = hpx.distributed_ones([200], distribution='block')\n",
    "darr_cyclic = hpx.distributed_full([150], 5.0, distribution='cyclic')\n",
    "\n",
    "print(\"String representations:\")\n",
    "print(f\"  {repr(darr_none)}\")\n",
    "print(f\"  {repr(darr_block)}\")\n",
    "print(f\"  {repr(darr_cyclic)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multilocality-header",
   "metadata": {},
   "source": [
    "## 3. Multi-Locality Concepts\n",
    "\n",
    "When running with multiple localities, here's how the components work together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spmd-header",
   "metadata": {},
   "source": [
    "### SPMD Pattern (Single Program, Multiple Data)\n",
    "\n",
    "The SPMD pattern runs the same program on all localities, each working on different data:\n",
    "\n",
    "```python\n",
    "# Each locality gets its portion of work\n",
    "my_id = hpx.locality_id()\n",
    "num_locs = hpx.num_localities()\n",
    "\n",
    "# Each locality processes its chunk\n",
    "chunk_size = total_size // num_locs\n",
    "my_start = my_id * chunk_size\n",
    "my_data = process(data[my_start:my_start + chunk_size])\n",
    "\n",
    "# Combine results\n",
    "global_result = hpx.all_reduce(my_data, op='sum')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spmd-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPMD example: Distributed sum\n",
    "def distributed_sum_example():\n",
    "    \"\"\"Example of SPMD pattern for distributed computation.\"\"\"\n",
    "    my_id = hpx.locality_id()\n",
    "    num_locs = hpx.num_localities()\n",
    "    \n",
    "    # Total problem size\n",
    "    total_size = 1000000\n",
    "    chunk_size = total_size // num_locs\n",
    "    \n",
    "    # Each locality works on its chunk\n",
    "    my_start = my_id * chunk_size\n",
    "    my_chunk = hpx.arange(my_start, my_start + chunk_size)\n",
    "    \n",
    "    # Compute local sum\n",
    "    local_sum = hpx.sum(my_chunk)\n",
    "    print(f\"Locality {my_id}: local sum = {local_sum}\")\n",
    "    \n",
    "    # Combine across all localities\n",
    "    global_sum = hpx.all_reduce(hpx.array([local_sum]), op='sum')\n",
    "    \n",
    "    return global_sum.to_numpy()[0]\n",
    "\n",
    "result = distributed_sum_example()\n",
    "expected = sum(range(1000000))\n",
    "print(f\"\\nGlobal sum: {result}\")\n",
    "print(f\"Expected:   {expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "launcher-header",
   "metadata": {},
   "source": [
    "### Multi-Locality Launcher\n",
    "\n",
    "HPXPy includes a launcher module for running across multiple processes:\n",
    "\n",
    "```python\n",
    "from hpxpy.launcher import launch_localities, spmd_main\n",
    "\n",
    "# Launch 4 localities running the same script\n",
    "launch_localities(\"my_script.py\", num_localities=4)\n",
    "\n",
    "# Or use the decorator\n",
    "@spmd_main(num_localities=4)\n",
    "def main():\n",
    "    with hpx.runtime():\n",
    "        # Distributed code here\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "launcher-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check launcher utilities\n",
    "from hpxpy.launcher import (\n",
    "    is_multi_locality_mode,\n",
    "    get_expected_num_localities,\n",
    "    LocalityConfig,\n",
    ")\n",
    "\n",
    "print(\"Launcher utilities:\")\n",
    "print(f\"  In multi-locality mode: {is_multi_locality_mode()}\")\n",
    "print(f\"  Expected localities: {get_expected_num_localities()}\")\n",
    "\n",
    "# Example of LocalityConfig\n",
    "config = LocalityConfig(\n",
    "    locality_id=0,\n",
    "    num_localities=4,\n",
    "    host=\"localhost\",\n",
    "    port=7910\n",
    ")\n",
    "print(f\"\\nExample HPX args for locality 0:\")\n",
    "for arg in config.to_hpx_args():\n",
    "    print(f\"  {arg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "hpx.finalize()\n",
    "print(\"Runtime finalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "### Collective Operations\n",
    "- `all_reduce(arr, op)` - Combine values across localities (sum, prod, min, max)\n",
    "- `broadcast(arr, root)` - Send data from root to all localities\n",
    "- `gather(arr, root)` - Collect data from all localities to root\n",
    "- `scatter(arr, root)` - Distribute data from root to all localities\n",
    "- `barrier(name)` - Synchronize all localities\n",
    "\n",
    "### Distributed Arrays\n",
    "- `distributed_zeros()`, `distributed_ones()`, `distributed_full()`, `distributed_from_numpy()`\n",
    "- Distribution policies: `none`, `block`, `cyclic`\n",
    "- Properties: `shape`, `size`, `ndim`, `policy`, `num_partitions`, `locality_id`\n",
    "- Methods: `to_numpy()`, `fill()`, `is_distributed()`, `get_distribution_info()`\n",
    "\n",
    "### Multi-Locality Support\n",
    "- SPMD pattern for distributed computing\n",
    "- `hpx.launcher` module for multi-process execution\n",
    "- `@spmd_main` decorator for automatic process spawning\n",
    "\n",
    "For more examples, see the `examples/` directory:\n",
    "- `distributed_reduction_demo.py` - SPMD pattern example\n",
    "- `multi_locality_demo.py` - Multi-process launch example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
