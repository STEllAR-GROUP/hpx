[/==============================================================================
    Copyright (C) 2007-2013 Hartmut Kaiser
    Copyright (C) 2011 Bryce Lelbach
    Copyright (C) 2013 Pyry Jahkola
    Copyright (C) 2013 Thomas Heller

    Distributed under the Boost Software License, Version 1.0. (See accompanying
    file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
===============================================================================/]

[/////////////////////////////////////////////////////////////////////////////]
[section:getting_started Getting Started]

[heading Welcome]

Welcome to the __hpx__ runtime system libraries! By the time you've completed this
tutorial, you'll be at least somewhat comfortable with __hpx__ and how to go about
using it.

[heading What's Here]

This document is designed to be an extremely gentle introduction, so we
included a fair amount of material that may already be very familiar to you.
To keep things simple, we also left out some information intermediate and
advanced users will probably want. At the end of this document, we'll refer
you to resources that can help you pursue these topics further.

[/Proofread by:]
[/Adrian Serio 3-13-12]
[/Phillip LeBlanc 3-13-12]

[/////////////////////////////////////////////////////////////////////////////]
[section:prereqs Prerequisites]

[heading Supported Platforms]

At this time, __hpx__ supports only the following platforms. Other platforms may
work, but we do not test __hpx__ with other platforms, so please be warned.

[table Supported Platforms for __hpx__
    [[Name   ][Recommended Version][Minimum Version][Architectures ]]
    [[Linux  ][3.2                ][2.6            ][x86-32, x86-64, k1om]]
    [[Windows][7, Server 2008 R2  ][Any NT system  ][x86-64]        ]
]

[heading Software and Libraries]

In the simplest case, __hpx__ depends on one set of libraries: __boost__. So,
before you read further, please make sure you have a recent version of
__boost__ installed on your target machine. __hpx__ currently requires at least
Boost V1.47.0 to work properly. It may build and run with older versions, but
we do not test __hpx__ with those versions, so please be warned.

Installing the Boost libraries is described in detail in Boost's own
__boost_getting_started__ document. It is often possible to download the Boost
libraries using the package manager of your distribution. Please refer to the
corresponding documentation for your system for more information.

The installation of Boost is described in detail in Boost's own
__boost_getting_started__ document. However, if you've never used the Boost
libraries (or even if you have), here's a quick primer: __boost_installation__.

In addition, we urge every user to have a recent version of hwloc installed on
the target system in order to have proper support for thread pinning and NUMA
awareness.

__hpx__ is written in 99% Standard C++. As such __hpx__ is compilable with
almost any standards compliant C++ compiler. A compiler supporting the C++11
Standard is highly recommended. We are currently support GCC, MSVC, ICPC and
clang. For the status of your favorite compiler with hpx visit __stellar_hpx_buildbot__.

[table Software Prerequisites for __hpx__ on Linux systems
    [[Name                       ][Recommended Version][Minimum Version ]]

    [[[*Compilers]]]
    [[__gcc__                    ][4.6.3              ][4.4.5           ]]
    [[__icpc__                   ][2013               ][2013            ]]

    [[[*Build System]]]
    [[__cmake__                  ][2.8.4              ][2.8.4           ]]

    [[[*Required Libraries]]]
    [[__boost_libraries__        ][1.48.0 or newer    ][1.47.0          ]]
    [[__hwloc__                  ][1.7                ][1.2             ]
        [Used for OS-thread pinning and NUMA awareness.]]
]

[table Software Prerequisites for __hpx__ on Windows systems
    [[Name                       ][Recommended Version][Minimum Version ]]

    [[[*Compilers]]]
    [[__visual_cxx__ (x64)       ][2010               ][2010            ]]

    [[[*Build System]]]
    [[__cmake__                  ][2.8.4              ][2.8.4           ]]

    [[[*Required Libraries]]]
    [[__boost__                  ][1.48.0 or newer    ][1.43.0          ]]
    [[__hwloc__                  ][1.7                ][1.5             ]
        [Used for OS-thread pinning and NUMA awareness.]]
]

[note You need to build the following Boost libraries for __hpx__:
      Boost.DateTime, Boost.Filesystem, Boost.ProgramOptions, Boost.Regex,
      Boost.Serialization, Boost.System, Boost.Thread, Boost.Chrono (starting
      Boost 1.47.0), and Boost.Atomic (starting Boost 1.53.0).]

Depending on the options you chose while building and installing __hpx__,
you will find that __hpx__ may depend on several other libraries such as those
listed below.

[table Highly Recommended Optional Software Prerequisites for __hpx__ on Linux systems
    [[Name                       ][Recommended Version][Minimum Version ][Notes]]

    [[__google_perftools__       ][1.7.1              ][1.7.1           ]
        [Used as a replacement for the system allocator, and for allocation
         diagnostics.]]
    [[__libunwind__              ][0.99               ][0.97            ]
        [Dependency of google-perftools on x86-64, used for stack unwinding.]]
    [[__hdf5__                   ][1.8.7              ][1.6.7           ]
        [Used for data I/O in the gravity, sheneos, neutron_star, interpolate1d
         and interpolate3d applications. See important note below.]]
]

[table Optional Software Prerequisites for __hpx__ on Linux systems
    [[Name                       ][Recommended Version][Minimum Version ][Notes]]

    [[__papi__                   ][                   ][                ]
        [Used for accessing hardware performance data.]]
    [[__lapack__                 ][                   ][                ]
        [Used in the neutron_star application.]]
    [[__blas__                   ][                   ][                ]
        [Used in the neutron_star application.]]
    [[__gsl__                    ][                   ][                ]
        [Used in the neutron_star application.]]
    [[__lorene__                 ][                   ][                ]
        [Used in the neutron_star application.]]
    [[__rnpl__                   ][1.11               ][1.11            ]
        [Used for data I/O in the adaptive1d and neutron_star applications.]]
    [[__jemalloc__               ][2.1.2              ][2.1.0           ]
        [Used as a replacement for the system allocator.]]
]

[table Highly Recommended Optional Software Prerequisites for __hpx__ on Windows systems
    [[Name                       ][Recommended Version][Minimum Version ][Notes]]

    [[__hdf5__                   ][1.8.7              ][1.6.7           ]
        [Used for data I/O in the gravity, sheneos, neutron_star, interpolate1d
         and interpolate3d applications. See important note below.]]
]

[important The C++ HDF5 libraries must be compiled with enabled threadsafety
           support. This has to be explicitly specified while configuring
           the HDF5 libraries as it is not the default. Additionally, you must
           set the following environment variables before configuring the HDF5
           libraries (this part only needs to be done on Linux):

           [teletype]
           ``
               $ export CFLAGS='-DHDatexit=""'
               $ export CPPFLAGS='-DHDatexit=""'
           ``
           ]

[endsect] [/ Prerequisites]

[/////////////////////////////////////////////////////////////////////////////]
[section:boost_installation Installing Boost Libraries]

The easiest way to create a working Boost installation is to compile Boost from
sources yourself. This is particularly important as many high performance
resources, even if they have Boost installed, usually only provide you with an
older version of Boost. We suggest you download the most recent release of the
Boost libraries from here: __boost_downloads__. Unpack the downloaded archive
into a directory of your choosing. We will refer to this directory a `$BOOST`.

Building and installing the Boost binaries is simple, regardless what platform
you are on:

    cd $BOOST
    bootstrap --prefix=<where to install boost>
    ./b2 -j<N>
    ./b2 install

where: `<where to install boost>` is the directory the built binaries will be
installed to, and `<N>` is the number of cores to use to build the Boost
binaries.

After the above sequence of command has been executed (this may take a while!)
you will need to specify the directory where Boost was installed as `BOOST_ROOT`
(`<where to install boost>`) while executing cmake for __hpx__ as explained in
detail in the sections __unix_installation__ and __windows_installation__.

[endsect]

[/////////////////////////////////////////////////////////////////////////////]
[section:unix_installation How to Install __hpx__ on Unix Variants]

[teletype]

* Create a build directory. __hpx__ requires an out-of-tree build. This means you
  will be unable to run CMake in the __hpx__ source tree.

``
    $ cd hpx
    $ mkdir my_hpx_build
    $ cd my_hpx_build
``

* Invoke CMake from your build directory, pointing the CMake driver to the root
  of your __hpx__ source tree.

``
    $ cmake -DBOOST_ROOT=/root/of/boost/installation \
        -DHWLOC_ROOT=/root/of/hwloc/installation
        [other CMake variable definitions] \
        /path/to/source/tree
``

[:for instance:]

``
    $ cmake -DBOOST_ROOT=~/packages/boost -DHWLOC=/packages/hwloc -DCMAKE_INSTALL_PREFIX=~/packages/hpx ~/downloads/hpx_0.9.6
``

* Invoke GNU make. If you are on a machine with multiple cores, add the -jN flag to
  your make invocation, where N is the number of parallel processes __hpx__ gets compiled with.

``
    $ gmake -j4
``

[caution Compiling and linking __hpx__ needs a considerable amount of memory. It is advisable that
    approximately 2 GB of memory per parallel process is available.]

[note Many Linux distributions use `make` as an alias for `gmake`]

* To complete the build and install __hpx__:

``
    $ gmake install
``

[important These commands will build and install the essential core components of
           __hpx__ only. In order to build and run the tests, please invoke:
           ``
               $ gmake tests
           ``
           and in order to build (and install) all examples invoke:
           ``
               $ gmake examples
               $ gmake install
           ``
           ]
[c++]

For more detailed information about using __cmake__ please refer its documentation
and also the section __cmake_hpx__. Please pay special attention to the section about
HPX_MALLOC as this is crucial for getting decent performance.

[endsect] [/ How to Install __hpx__ on Unix Variants]

[/////////////////////////////////////////////////////////////////////////////]
[section:macos_installation How to Install __hpx__ on OS X (Mac)]

This section describes how to build__hpx__ for OS X (Mac) (with recent versions
of Clang, libc++, and Boost).

[teletype]

The standard system compiler on OS X is too old to build HPX. You will
have to install a newer compiler manually, either Clang or GCC. Below
we describe two possibilities:

[heading Install a recent version of LLVM and Clang]

    In order to build __hpx__ you will need a fairly recent version of Clang
    (at least version 3.2 of Clang and LLVM). For more instructions please see
    [link http://clang.llvm.org/get_started.html here].

    If you're using Homebrew, `brew install llvm --with-clang` will do the trick
    and install 3.2 into `/usr/local/bin`.

    In the guide below, I assume you're either using Clang 3.2 as installed by
    Homebrew into /usr/local/bin, or that the following symlinks are created and
    visible in your $PATH:
``
        ln -s /path/to/build-llvm/Release/bin/clang++ clang++-3.3
        ln -s /path/to/build-llvm/Release/bin/clang clang-3.3
``
    (Replace `/path/to` here with an absolute path of your liking.)

[heading Visit http://libcxx.llvm.org/ to get the latest version of the "libc++" C++ standard library]

    You need to use the trunk version; what's currently bundled with XCode or
    OS X aren't quite there yet. You can follow the steps in
    http://libcxx.llvm.org/ if you choose, but here's briefly how it can be built:
``
        cd /path/to
        git clone http://llvm.org/git/libcxx.git
        cd libcxx/lib
        CXX=clang++-3.3 CC=clang-3.3 TRIPLE=-apple- ./buildit
``
    or alternatively:
``
        CXX=/usr/local/bin/clang++ CC=/usr/local/bin/clang TRIPLE=-apple- \
            ./buildit
``
    The library is then found in `/path/to/libcxx/include` and
    `/path/to/libcxx/lib`, respectively

[heading Build (and install) a recent version of Boost, using Clang and libc++]

    To build Boost with Clang and make it link to libc++ as standard library,
    you'll need to set up either of the following in your `~/user-config.jam`
    file:
``
        # user-config.jam (put this file into your home directory)
        # ...

        # Clang 3.2
        using clang
            : 3.2
            : "/usr/local/bin/clang++"
            : <cxxflags>"-std=c++11 -stdlib=libc++ -fcolor-diagnostics -isystem /path/to/libcxx/include"
              <linkflags>"-stdlib=libc++ -L/path/to/libcxx/lib"
            ;

        # Clang trunk ("3.3" for convenience)
        using clang
            : 3.3
            : "clang++-3.3"
            : <cxxflags>"-std=c++11 -stdlib=libc++ -fcolor-diagnostics -isystem /path/to/libcxx/include"
              <linkflags>"-stdlib=libc++ -L/path/to/libcxx/lib"
            ;
``
    (Again, remember to replace `/path/to` with whatever you used earlier.)

    You can then use as build command either:
``
        b2 --build-dir=/tmp/build-boost --layout=versioned toolset=clang-3.2 install -j4
``
    or
``
        b2 --build-dir=/tmp/build-boost --layout=versioned toolset=clang-3.3 install -j4
``
    we verifed this using Boost V1.53. If you use a different
    version, just remember to replace `/usr/local/include/boost-1_53` with
    whatever include prefix you had in your installation.

[heading Build HPX, finally]
``
        cd /path/to
        git clone https://github.com/STEllAR-GROUP/hpx.git
        mkdir build-hpx && cd build-hpx
``
    To build with Clang 3.2, execute:
``
        cmake ../hpx \
            -DCMAKE_CXX_COMPILER=/usr/local/bin/clang++ \
            -DCMAKE_C_COMPILER=/usr/local/bin/clang-3.3 \
            -DBOOST_INCLUDE_DIR=/usr/local/include/boost-1_53 \
            -DBOOST_LIBRARY_DIR=/usr/local/lib \
            -DBOOST_SUFFIX=-clang-darwin32-mt-1_53 \
            -DCMAKE_CXX_FLAGS="-isystem /path/to/libcxx/include" \
            -DLINK_FLAGS="-L /path/to/libcxx/lib"
        make
``
    To build with Clang 3.3 (trunk), execute:
``
        cmake ../hpx \
            -DCMAKE_CXX_COMPILER=clang++-3.3 \
            -DCMAKE_C_COMPILER=clang-3.3 \
            -DBOOST_INCLUDE_DIR=/usr/local/include/boost-1_53 \
            -DBOOST_LIBRARY_DIR=/usr/local/lib \
            -DBOOST_SUFFIX=-clang-darwin33-mt-1_53 \
            -DCMAKE_CXX_FLAGS="-isystem /path/to/libcxx/include" \
            -DLINK_FLAGS="-L /path/to/libcxx/lib"
        make
``

For more detailed information about using __cmake__ please refer its documentation
and to the section __cmake_hpx__ for. Please pay special attention to the section about
HPX_MALLOC as this is crucial for getting decent performance.

[heading Alternative Installation method of HPX on OS X (Mac)]

Alternatively, you can install a recent version of gcc as well as all
required libraries via MacPorts:

# Install __macports__

# Install CMake, gcc 4.8, and hwloc:
``
   $ sudo port install gcc48
   $ sudo port install hwloc
``
   You may also want:
``
   $ sudo port install cmake
   $ sudo port install git-core
``
# Make this version of gcc your default compiler:
``
   $ sudo port install gcc_select
   $ sudo port select gcc mp-gcc48
``
# Build Boost manually (the Boost package of MacPorts is built with Clang, and unfortunately doesn't work with a GCC-build version of HPX):
``
   wget http://sourceforge.net/projects/boost/files/boost/1.54.0/boost_1_54_0.tar.bz2
   tar xjf boost_1_54_0.tar.bz2
   pushd boost_1_54_0
   export BOOST_DIR=$HOME/boost_1_54_0
   ./bootstrap.sh --prefix=$BOOST_DIR
   ./b2 -j8
   ./b2 -j8 install
   export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:$BOOST_DIR/lib
   popd
``
# Build HPX:
``
   git clone https://github.com/STEllAR-GROUP/hpx.git
   mkdir hpx-build
   pushd hpx-build
   export HPX_DIR=$HOME/hpx
   cmake -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++ -DCMAKE_FORTRAN_COMPILER=gfortran -DCMAKE_C_FLAGS="-Wno-unused-local-typedefs" -DCMAKE_CXX_FLAGS="-Wno-unused-local-typedefs" -DBOOST_ROOT=$BOOST_DIR -DHWLOC_ROOT=/opt/local -DCMAKE_INSTALL_PREFIX=$HOME/hpx $(pwd)/../hpx
   make -j8
   make -j8 install
   export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:$HPX_DIR/lib/hpx
   popd
``

# Note that you need to set BOOST_DIR, HPX_DIR, and DYLD_LIBRARY_PATH (for both BOOST_DIR and HPX_DIR) every time you configure, build, or run an HPX application.

# If you want to use HPX with MPI, you need to enable the MPI parcelport, and also specify the location of the MPI wrapper scripts. This can be done e.g. with the following command:
``
   cmake -DHPX_HAVE_PARCELPORT_MPI=ON -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++ -DCMAKE_FORTRAN_COMPILER=gfortran -DMPI_C_COMPILER=openmpicc -DMPI_CXX_COMPILER=openmpic++ -DMPI_FORTRAN_COMPILER=openmpif90 -DCMAKE_C_FLAGS="-Wno-unused-local-typedefs" -DCMAKE_CXX_FLAGS="-Wno-unused-local-typedefs" -DBOOST_ROOT=$BOOST_DIR -DHWLOC_ROOT=/opt/local -DCMAKE_INSTALL_PREFIX=$HOME/hpx $(pwd)/../hpx
``


[c++]
[endsect]

[/////////////////////////////////////////////////////////////////////////////]
[section:windows_installation How to Install __hpx__ on Windows]

[heading Installation of Required Prerequisites]

* Download the Boost c++ libraries from __boost_downloads__
* Install the boost library as explained in the section __boost_installation__
* Download the latest version of __cmake__ binaries, which are located under
  the platform section of the downloads page at __cmake_download__.
* Download the latest version of __hpx__ from the __stellar__ website:
  __stellar_hpx_download__

[heading Installation of the __hpx__ Library]

* Create a build folder. __hpx__ requires an out-of-tree-build. This means that you
  will be unable to run CMake in the __hpx__ source folder.
* Open up the CMake GUI. In the input box labelled "Where is the source code:",
  enter the full path to the source folder. The source directory is one where the
  sources were checked out. CMakeLists.txt files in the source directory as well as the
  subdirectories describe the build to CMake. In addition to this, there are CMake
  scripts (usually ending in .cmake) stored in a special CMake directory. CMake does not
  alter any file in the source directory and   doesn't add new ones either. In the input
  box labelled "Where to build the binaries:", enter the full path to the build folder you
  created before. The build directory is one where all compiler outputs are stored, which
  includes object files and final executables.
* Add CMake variable definitions (if any) by clicking the "Add Entry" button.
  There are two required variables you need to define: `BOOST_ROOT` and
  `HWLOC_ROOT`. These (PATH) variables need to be set to point to the root
  folder of your __boost__ and __hwloc__ installations.
  It is recommended to set the variable `CMAKE_INSTALL_PREFIX` as
  well. This determines where the HPX libraries will be built and installed.
  If this (PATH) variable is set, it has to refer to the directory where the
  built __hpx__ files should be installed to.
* Press the "Configure" button. A window will pop up asking you which compilers
  to use. Select the Visual Studio 10 (64Bit) compiler (it usually is
  the default if available). The Visual Studio 2012 (64Bit) compiler is
  supported as well. Note that while it is possible to build HPX for x86,
  we don't recommend doing so as 32 bit runs are severely restricted by a 32 bit
  Windows system limitation affecting the number of HPX threads you can create.
* Make sure that that the `CMAKE_BUILD_TYPE` (under the `CMAKE` tree)
  is set to `Debug` or `Release`, according to what you plan to do (alternatively,
  this variable can be set to `RelWithDebInfo` or `MinSizeRel`). The text area at
  the bottom of CMake GUI displays the output of CMake. CMake prompts an error message
  in a separate dialog box if a required dependency is not found.
* Press "Configure" again. Repeat this step until the "Generate" button becomes
  clickable (and until no variable definitions are marked red anymore).
* Press "Generate".
* Open up the build folder, and double-click hpx.sln.
* Build the INSTALL target.

For more detailed information about using __cmake__ please refer its documentation
and also the section __cmake_hpx__.

[endsect] [/ How to Install __hpx__ on Windows]

[section:intel_mic_installation How to Install __hpx__ on the Xeon Phi]

[heading Installation of the Boost Libraries]

* Download __boost_downloads__ for Linux and unpack the retreived tarball.

* Adapt your ~/user-config.jam to contain the following lines:
```
        ## Toolset to be used for compiling for the host
        using intel
            : host
            :
            : <cxxflags>"-std=c++0x"
            ;

        ## Toolset to be used for compiling for the Xeon Phi
        using intel
            : mic
            :
            : <cxxflags>"-std=c++0x -mmic"
              <linkflags>"-std=c++0x -mmic"
            ;
```
[teletype]
* Change to the directory you unpacked boost in (from now on referred to as $BOOST_ROOT)
  and execute the following commands:
```
        $ ./bootstrap.sh
        $ ./b2 toolset=intel-mic -j<N>
```
  You should now have all the required boost libraries.

[heading Installation of the hwloc Library]

* Download __hwloc_downloads__, unpack the retreived tarball and change to the newly
  created directory
* Run the configure-make-install procedure as follows:
```
        $ CC=icc CFLAGS=-mmic CXX=icpc CXXFLAGS=-mmic LDFLAGS=-mmic ./configure --host=k1om --prefix=$HWLOC_ROOT
        $ make
        $ make install
```
You now have a working hwloc installation in $HWLOC_ROOT.

[heading Building __hpx__]

After all the prerequistes have been succesfully installed, we can now start building and
installing __hpx__. The build procedure is almost the same as for __unix_installation__
with the sole difference that you have to enable the Xeon Phi in the CMake Build system.
This is achieved by invoking CMake in the following way:
```
        cmake                         \
            -DCMAKE_CXX_COMPILER=icpc \
            -DCMAKE_C_COMPILER=icc    \
            -DHPX_NATIVE_MIC=On       \
            -DBOOST_ROOT=$BOOST_ROOT  \
            -DHWLOC_ROOT=$HWLOC_ROOT  \
            /path/to/hpx
```
[c++]
For more detailed information about using __cmake__ please refer its documentation
and to the section __cmake_hpx__. Please pay special attention to the section about
HPX_MALLOC as this is crucial for getting decent performance on the Xeon Phi.

[endsect] [/ How to Install __hpx__ on the Xeon Phi]

[/////////////////////////////////////////////////////////////////////////////]
[section:unix_pbs How to Use __hpx__ Applications with PBS]

[teletype]

Most __hpx__ applications are executed on parallel computers.  These platforms
typically provide integrated job management services that facilitate the
allocation of computing resources for each parallel program. __hpx__ includes out of
the box support for one of the most common job management systems, the Portable
Batch System (PBS).

All PBS jobs require a script to specify the resource requirements and other
parameters associated with a parallel job. The PBS script is basically a shell
script with PBS directives placed within commented sections at the beginning of
the file. The remaining (not commented-out) portions of the file executes just
like any other regular shell script. While the description of all available PBS
options is outside the scope of this tutorial (the interested reader may refer
to in-depth [@http://www.clusterresources.com/torquedocs21/ documentation] for
more information), below is a minimal example to illustrate the approach. As a
test application we will use the multithreaded [^hello_world] program, explained
in the section __hello_world_example__.

```
    #!/bin/bash
    #
    #PBS -l nodes=2:ppn=4

    APP_PATH=~/packages/hpx/bin/hello_world
    APP_OPTIONS=

    __pbsdsh__ -u $APP_PATH $APP_OPTIONS ``[hpx_cmdline --hpx:nodes]``=`cat $PBS_NODEFILE`
```

[caution If the first application specific argument (inside `$APP_OPTIONS`)
         is a non-option (i.e. does not start with a '`-`' or a '`--`', then those
         have to be placed before the option [hpx_cmdline --hpx:nodes], which
         in this case should be the last option on the command line.

         Alternatively, use the option [hpx_cmdline --hpx:endnodes] to explicitly
         mark the end of the list of node names:
         ```
         __pbsdsh__ -u $APP_PATH ``[hpx_cmdline --hpx:nodes]``=`cat $PBS_NODEFILE` ``[hpx_cmdline --hpx:endnodes] ``$APP_OPTIONS
         ```
         ]

The [^#PBS -l nodes=2:ppn=4] directive will cause two compute nodes to be
allocated for the application, as specified in the option [^nodes]. Each of the
nodes will dedicate four cores to the program, as per the option [^ppn], short
for "processors per node" (PBS does not distinguish between processors and
cores). Note that requesting more cores per node than physically available is
pointless and may prevent PBS from accepting the script.

[^APP_PATH] and [^APP_OPTIONS] are shell variables that respectively specify
the correct path to the executable ([^hello_world] in this case) and the
command line options. Since the [^hello_world] application doesn't need any
command line options, [^APP_OPTIONS] has been left empty. Unlike in other
execution environments, there is no need to use the [hpx_cmdline
[^--hpx:threads]] option to indicate the required number of OS threads per
node; the __hpx__ library will derive this parameter automatically from PBS.

Finally, __pbsdsh__ is a PBS command that starts tasks to the resources allocated
to the current job. It is recommended to leave this line as shown and modify
only the PBS options and shell variables as needed for a specific application.

[important A script invoked by __pbsdsh__ starts in a very basic environment:
           the user's `$HOME` directory is defined and is the current directory,
           the `LANG` variable is set to `C`, and the `PATH` is set to the basic
           `/usr/local/bin:/usr/bin:/bin` as defined in a system-wide file
           pbs_environment. Nothing that would normally be set up by a system
           shell profile or user shell profile is defined, unlike the
           environment for the main job script.]

Another choice is for the __pbsdsh__ command in your main job script to invoke
your program via a shell, like `sh` or `bash`, so that it gives an initialized
environment for each instance. We create a small script `runme.sh` which is
used to invoke the program:

``
    #!/bin/bash
    # Small script which invokes the program based on what was passed on its
    # command line.
    #
    # This script is executed by the bash shell which will initialize all
    # environment variables as usual.
    $@
``

Now, we invoke this script using the __pbsdsh__ tool:

```
    #!/bin/bash
    #
    #PBS -l nodes=2:ppn=4

    APP_PATH=~/packages/hpx/bin/hello_world
    APP_OPTIONS=

    __pbsdsh__ -u runme.sh $APP_PATH $APP_OPTIONS ``[hpx_cmdline --hpx:nodes]``=`cat $PBS_NODEFILE`
```

All that remains now is submitting the job to the queuing system. Assuming that
the contents of the PBS script were saved in file [^pbs_hello_world.sh] in the
current directory, this is accomplished by typing:

``
    $ __qsub__ ./pbs_hello_world_pbs.sh
``

If the job is accepted, __qsub__ will print out the assigned job ID, which may
look like:

``
    $ 42.supercomputer.some.university.edu
``

To check the status of your job, issue the following command:

``
    $ __qstat__ 42.supercomputer.some.university.edu
``

and look for a single-letter job status symbol. The common cases include:

* *Q* - signifies that the job is queued and awaiting its turn to be executed.
* *R* - indicates that the job is currently running.
* *C* - means that the job has completed.

The example __qstat__ output below shows a job waiting for execution resources
to become available:

``
    Job id                    Name             User            Time Use S Queue
    ------------------------- ---------------- --------------- -------- - -----
    42.supercomputer          ...ello_world.sh joe_user               0 Q batch
``

After the job completes, PBS will place two files, [^pbs_hello_world.sh.o42] and
[^pbs_hello_world.sh.e42], in the directory where the job was submitted. The
first contains the standard output and the second contains the standard error
from all the nodes on which the application executed. In our example, the error
output file should be empty and standard output file should contain something
similar to:

``
    hello world from OS-thread 3 on locality 0
    hello world from OS-thread 2 on locality 0
    hello world from OS-thread 1 on locality 1
    hello world from OS-thread 0 on locality 0
    hello world from OS-thread 3 on locality 1
    hello world from OS-thread 2 on locality 1
    hello world from OS-thread 1 on locality 0
    hello world from OS-thread 0 on locality 1
``

Congratulations! You have just run your first distributed __hpx__ application!

[c++]

[endsect] [/ How to Use __hpx__ Applications with PBS]

[section:unix_slurm How to Use __hpx__ Applications with SLURM]

Just like PBS (described in section __using_pbs__), __slurm__ is a job management
system which is widely used on large supercomputing systems. Any __hpx__
application can easily be run using SLURM. This section describes how this can
be done.

The easiest way to run an __hpx__ application using SLURM is to utilize the
command line tool __srun__ which interacts with the SLURM batch scheduling
system.

```
    srun -p <partition> -N <number-of-nodes> hpx-application <application-arguments>
```

Here, `<partition>` is one of the node partitions existing on the target machine
(consult the machines documentation to get a list of existing partitions) and
`<number-of-nodes>` is the number of compute nodes you want to use. By default,
the HPX application is started with one locality per node and uses all available
cores on a node. You can change the number of localities started per node (for
example to account for NUMA effects) by specifying the `-n` option of srun. The
number of cores per locality can be set by `-c`. The `<application-arguments>`
are any application specific arguments which need to passed on to the
application.

[note There is no need to use any of the __hpx__ command line options related to
      the number of localities, number of threads, or related to networking
      ports. All of this information is automatically extracted from the SLURM
      environment by the __hpx__ startup code.]

[important The __srun__ documentation explicitly states: "If `-c` is specified
      without `-n`, as many tasks will be allocated per node as possible while
      satisfying the `-c` restriction. For instance on a cluster with 8 CPUs per
      node, a job request for 4 nodes and 3 CPUs per task may be allocated 3 or
      6 CPUs per node (1 or 2 tasks per node) depending upon resource consumption
      by other jobs."
      For this reason, we suggest to always specify `-n <number-of-instances>`,
      even if `<number-of-instances>` is equal to one (`1`).]

[heading Interactive Shells]

To get an interactive development shell on one of the nodes you can issue the
following command:

```
     srun -p <node-type> -N <number-of-nodes> --pty /bin/bash -l
```

After the shell has been opened, you can run your HPX application. By default,
it uses all available cores. Note that if you requested one node, you don't
need to do `srun` again. However, if you requested more than one nodes, and want
to run your distributed application, you can use `srun` again to start up the
distributed HPX application. It will use the resources that have been requested
for the interactive shell.

[heading Scheduling Batch Jobs]

The above mentioned method of running __hpx__ applications is fine for
development purposes. The disadvantage that comes with `srun` is that it only
returns once the application is finished. This might not be appropriate for
longer running applications (for example benchmarks or larger scale simulations).
In order to cope with that limitation you can use the __sbatch__ command.

The `sbatch` command expects a script that it can run once the requested
resources are available. In order to request resources you need to add
`#SBATCH` comments in your script or provide the necessary parameters to
`sbatch` directly. The parameters are the same as with `srun`. The commands you
need to execute are the same you would need to start your application as if you
were in an interactive shell.

[endsect]

[/Proofread by:]
[/Adrian Serio 3-13-12]
[/Phillip LeBlanc 3-13-12]

[endsect] [/ Getting Started]

[/Proofread by:]
[/Adrian Serio 3-13-12]
[/Thomas Heller 07-26-13]


