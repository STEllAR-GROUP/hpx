[/=============================================================================
    Copyright (C) 2013 Patricia Grubel
    Copyright (C) 2007-2013 Hartmut Kaiser

    Distributed under the Boost Software License, Version 1.0. (See accompanying
    file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
=============================================================================/]

[section:schedulers __hpx__ Thread Scheduling Policies]

The HPX runtime has seven thread scheduling policies: priority_local, local,
global, abp, abp-priority, hierarchy and periodic priority. These policies can
be specified from the command line using the command line option
[hpx_cmdline `--hpx:queuing`]. In order to use a particular scheduling policy,
the runtime system must be built with the appropriate scheduler flag turned on
(e.g. `cmake -DHPX_LOCAL_SCHEDULER=ON`, see __cmake_options__ for more
information).

[heading Priority Local Scheduling Policy (default policy)]

* default or invoke using: [hpx_cmdline `--hpx:queuing=priority_local`] (or `-qpr`)

The priority local scheduling policy maintains one queue per operating system
(OS) thread. The OS thread pulls its work from this queue. By default the number
of high priority queues is equal to the number of OS threads; the number of
high priority queues can be specified on the command line using
[hpx_cmdline `--hpx:high-priority-threads`]. High priority threads are executed
by any of the OS threads before any other work is executed. When a queue is
empty work will be taken from high priority queues first. There is one low
priority queue from which threads will be scheduled only when there is no other
work.

For this scheduling policy there is an option to turn on NUMA sensitivity using
the command line option  [hpx_cmdline `--hpx:numa-sensitive`]. When NUMA
sensitivity is turned on work stealing is done from queues associated with the
same NUMA domain first, only after that work is stolen from other NUMA domains.

[heading Local Scheduling Policy]

* invoke using: [hpx_cmdline `--hpx:queuing=local`] (or `-ql`)
* flag to turn on for build: `HPX_LOCAL_SCHEDULER`

The local scheduling policy maintains one queue per OS thread from which each
OS thread pulls its tasks (user threads).

[heading Global Scheduling Policy]

* invoke using: [hpx_cmdline `--hpx:queuing global`] or -qg
* flag to turn on for build: `HPX_GLOBAL_SCHEDULER`

The global scheduling policy maintains one shared queue from which all OS
threads pull tasks.


[heading ABP Scheduling Policy]

* invoke using: [hpx_cmdline `--hpx:queuing=abp`] (or `-qa`)
* flag to turn on for build: `HPX_ABP_SCHEDULER`

The ABP scheduling policy maintains a double ended lock free queue  for each
OS thread. Threads are pushed on the top of the queue, and during work stealing
threads are taken from the bottom of the queue.

[heading Priority ABP Scheduling Policy]

* invoke using: [hpx_cmdline `--hpx:queuing=priority_abp`]
* flag to turn on for build: `HPX_ABP_PRIORITY_SCHEDULER`

Priority ABP policy maintains a double ended lock free queue for each OS thread.
By default the number of high priority queues is equal to the number of OS
threads; the number of high priority queues can be specified on the command
line using  [hpx_cmdline `--hpx:high-priority-threads`]. High priority threads
are executed by the first OS threads before any other work is executed. When
a queue is empty work will be taken from high priority queues first. There is
one low priority queue from which threads will be scheduled only when there is
no other work. For this scheduling policy there is an option to turn on NUMA
sensitivity using the command line option [hpx_cmdline `--hpx:numa-senstive`].
When NUMA sensitivity is turned on work stealing is done from queues associated
with the same NUMA domain first, only after that work is stolen from other NUMA
domains.

[heading Hierarchy Scheduling Policy]

* invoke using: [hpx_cmdline `--hpx:queuing=hierarchy`] (or `-qh`)
* flag to turn on for build: `HPX_HIERARCHY_SCHEDULER`

The hierarchy policy maintains a tree of work items. Every OS thread walks the
tree to obtain new work.  Arity of the thread queue tree can be specified on
the command line using [hpx_cmdline `--hpx:hierarchy-arity`] (default is 2).
Work stealing is done from the parent queue in that tree.

[heading Periodic Priority Scheduling Policy]

* invoke using: [hpx_cmdline `--hpx:queuing=periodic`] (or `-qpe`)
* flag to turn on for build: `HPX_PERIODIC_PRIORITY_SCHEDULER`

Maintains one queue of work items (user threads) for each OS thread. Maintains 
a number of high priority queues (specified by 
[hpx_cmdline `--hpx:high-priority-threads`]) and one low priority queue. High 
priority threads are executed by the specified number of OS threads before any 
other work is executed. Low priority threads are executed when no other work 
is available.

[/
    Questions, concerns and notes:

    Are all the work queues FIFO except perhaps the deque ABP?

    What is the low priority thread for priority policies?
    One of the comments says that there are exactly one queue per OS threads 
    then an additional number of high-priority-threads queues plus an additional 
    low priority queue.

    Documentation claims –hpx:high-priority-threads option only available for 
    local priority but is accepted on command line for both periodic priority 
    and abd priority (same for error messages)

    Is numa-sensitive only for local priority??? I know it says that in the 
    documentation and error messages but seems to be available for abp 
    priority and periodic priority

    There should be some way of verifying which policy is being used.

    --hpx-high-priority-threads option ********* it seems to me this option 
    should be =< number of OS threads but command line accepts any number. 
    Okay so I'm confused, in the documentation for command line options it 
    states: the number of operating system threads maintaining a high priority 
    queue (default: number of OS threads), valid for 
    --hpx:queuing=priority_local only examples/spell_check/example_text.txt
    but in hpx_init.cpp the comment states: local scheduler with priority queue 
    (one queue for each OS threads plus one separate queue for high priority 
    HPX-threads)


    SCHEDULER
    initialization parameters:
    max count per queue (1000) this is for all policies
    number of queues  (OS threads) all except global
    number of high priority queues (selectable on command line  local priority, 
    periodic and abp priority policies)
    minimum add thread count (10)  for periodic priority policy the number of 
    threads will be incremented in steps of this count


    maximum number of active threads = 1000 is that per queue? I don't understand 
    the comment:
    The maximum number of active threads this thread manager should

    // create. This number will be a constraint only as long as the work
    // items queue is not empty. Otherwise the number of active threads
    // will be incremented in steps equal to the \a min_add_new_count
    // specified above.
    enum { max_thread_count = 1000 };

    I see both FIFO and double ended queues in ABP policies?
]

[endsect]


