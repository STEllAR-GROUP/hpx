[/=============================================================================
    Copyright (C) 2012 Bryce Adelstein-Lelbach
    Copyright (C) 2007-2016 Hartmut Kaiser

    Distributed under the Boost Software License, Version 1.0. (See accompanying
    file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
=============================================================================/]

[section:lcos Using LCOs]

Lightweight Control Objects provide synchronization for HPX applications. Most
of them are familiar from other frameworks, but a few of them work in slightly
special different ways adapted to HPX.

# future

# queue

# object_semaphore

# barrier

[heading Channels]

Channels combine communication (the exchange of a value) with
synchronization (guaranteeing that two calculations (tasks) are in a known
state). A channel can transport any number of values of a given type from
a sender to a receiver:

    hpx::lcos::local::channel<int> c;
    c.set(42);
    cout << c.get();      // will print '42'

Channels can be handed to another thread (or in case of channel components,
to other localities), thus establishing a communication channel between two
independent places in the program:

    void do_something(
        hpx::lcos::local::receive_channel<int> c,
        hpx::lcos::local::send_channel<> done)
    {
        cout << c.get();        // prints 42
        done.set();             // signal back
    }

    {
        hpx::lcos::local::channel<int> c;
        hpx::lcos::local::channel<> done;

        hpx::apply(&do_something, c, done);

        c.set(42);              // send some value
        done.get();             // wait for thread to be done
    }

A channel component is created on one locality and can be send to another
locality using an action. This example also demonstrates how a channel can be
used as a range of values:

    // channel components need to be registered for each used type (not needed
    // for hpx::lcos::local::channel)
    HPX_REGISTER_CHANNEL(double);

    void some_action(hpx::lcos::channel<double> c)
    {
        for (double d : c)
            hpx::cout << d << std::endl;
    }
    HPX_REGISTER_ACTION(some_action);

    {
        // create the channel on this locality
        hpx::lcos::channel<double> c(hpx::find_here());

        // pass the channel to a (possibly remote invoked) action
        hpx::apply(some_action(), hpx::find_here(), c);

        // send some values to the receiver
        std::vector<double> v = { 1.2, 3.4, 5.0 };
        for (double d : v)
            c.set(d);

        // explicitly close the communication channel (implicit at destruction)
        c.close();
    }

[heading Composable Guards]

Composable guards operate in a manner similar to locks, but
are applied only to asynchronous functions. The guard (or guards) is automatically
locked at the beginning of a specified task and automatically unlocked at the end.
Because guards are never added to an existing task's execution context, the calling
of guards is freely composable and can never deadlock.

To call an application with a single guard, simply declare the guard and call
run_guarded() with a function (task).

     hpx::lcos::local::guard gu;
     run_guarded(gu,task);

If a single method needs to run with multiple guards, use a guard set.

     boost::shared<hpx::lcos::local::guard> gu1(new hpx::lcos::local::guard());
     boost::shared<hpx::lcos::local::guard> gu2(new hpx::lcos::local::guard());
     gs.add(*gu1);
     gs.add(*gu2);
     run_guarded(gs,task);

Guards use two atomic operations (which are not called repeatedly)
to manage what they do, so overhead should be extremely low.

# conditional_trigger

# counting_semaphore

# dataflow

# event

# mutex

# once

# recursive_mutex

# spinlock

# spinlock_no_backoff

# trigger

[section:extend_futures Extended Facilities for Futures]

Concurrency is about both decomposing and composing the program from the parts
that work well individually and together. It is in the composition of connected
and multicore components where today's C++ libraries are still lacking.

The functionality of `std::future` offers a partial solution. It allows for the
separation of the initiation of an operation and the act of waiting for its
result; however the act of waiting is synchronous. In communication-intensive
code this act of waiting can be unpredictable, inefficient and simply
frustrating. The example below illustrates a possible synchronous wait using
futures.

    #include <future>
    using namespace std;
    int main()
    {
        future<int> f = async([]() { return 123; });
        int result = f.get(); // might block
    }

For this reason, __hpx__ implements a set of extensions to `std::future` (as
proposed by __cpp11_n4107__). This proposal introduces the following key
asynchronous operations to `hpx::future`, `hpx::shared_future`, and
`hpx::async`, which enhance and enrich these facilities.

[table Facilities extending std::future
 [[Facility][Description]]
 [[`hpx::future::then`]
  [In asynchronous programming, it is very common for one
    asynchronous operation, on completion, to invoke a second operation and pass
    data to it. The current C++ standard does not allow one to register a
    continuation to a future. With `then`, instead of waiting for the result, a
    continuation is "attached" to the asynchronous operation, which is invoked
    when the result is ready. Continuations registered using then function
    will help to avoid blocking waits or wasting threads on polling, greatly
    improving the responsiveness and scalability of an application.]]
 [[unwrapping constructor for `hpx::future`]
  [In some scenarios, you might want to create a future that returns another
   future, resulting in nested futures.
   Although it is possible to write code to unwrap the outer future and retrieve
   the nested future and its result, such code is not easy to write because you
   must handle exceptions and it may cause a blocking call. Unwrapping can allow
   us to mitigate this problem by doing an asynchronous call to unwrap the
   outermost future.]]
 [[`hpx::future::is_ready`]
  [There are often situations where a `get()` call on a
   future may not be a blocking call, or is only a blocking call under certain
   circumstances. This function gives the ability to test for early completion and
   allows us to avoid associating a continuation, which needs to be scheduled with
   some non-trivial overhead and near-certain loss of cache efficiency.]]
 [[`hpx::make_ready_future`]
  [Some functions may know the value at the point of construction. In these cases
   the value is immediately available, but needs to be returned as a future. By
   using `hpx::make_ready_future` a future can be created which holds a pre-computed
   result in its shared state. In the current standard it is non-trivial to create
   a future directly from a value. First a promise must be created, then the promise
   is set, and lastly the future is retrieved from the promise. This can now be
   done with one operation.]]
]

The standard also omits the ability to compose multiple futures. This is a
common pattern that is ubiquitous in other asynchronous frameworks and is
absolutely necessary in order to make C++ a powerful asynchronous programming
language. Not including these functions is synonymous to Boolean algebra
without AND/OR.

In addition to the extensions proposed by __cpp11_n4107__, __hpx__ adds functions
allowing to compose several futures in a more flexible way.

[table Facilities for Composing hpx::futures
 [[Facility][Description][Comment]]
 [[[funcref hpx::when_any `hpx::when_any`],[br]
   [funcref hpx::when_any_n `hpx::when_any_n`]]
  [Asynchronously wait for at least one of multiple future or shared_future
   objects to finish.][__cpp11_n4107__, `..._n` versions are __hpx__ only]]
 [[[funcref hpx::wait_any `hpx::wait_any`],[br]
   [funcref hpx::wait_any_n `hpx::wait_any_n`]]
  [Synchronously wait for at least one of multiple future or shared_future
   objects to finish.][__hpx__ only]]

 [[[funcref hpx::when_all `hpx::when_all`],[br]
   [funcref hpx::when_all_n `hpx::when_all_n`]]
  [Asynchronously wait for all future and shared_future objects to finish.]
  [__cpp11_n4107__, `..._n` versions are __hpx__ only]]
 [[[funcref hpx::wait_all `hpx::wait_all`],[br]
   [funcref hpx::wait_all_n `hpx::wait_all_n`]]
  [Synchronously wait for all future and shared_future objects to finish.]
  [__hpx__ only]]

 [[[funcref hpx::when_some `hpx::when_some`],[br]
   [funcref hpx::when_some_n `hpx::when_some_n`]]
  [Asynchronously wait for multiple future and shared_future objects to finish.]
  [__hpx__ only]]
 [[[funcref hpx::wait_some `hpx::wait_some`],[br]
   [funcref hpx::wait_some_n `hpx::wait_some_n`]]
  [Synchronously wait for multiple future and shared_future objects to finish.]
  [__hpx__ only]]

 [[[funcref hpx::when_each `hpx::when_each`],[br]
   [funcref hpx::when_each_n `hpx::when_each_n`]]
  [Asynchronously wait for multiple future and shared_future objects to finish
   and call a function for each of the future objects as soon as it becomes
   ready.]
  [__hpx__ only]]
 [[[funcref hpx::wait_each `hpx::wait_each`],[br]
   [funcref hpx::wait_each_n `hpx::wait_each_n`]]
  [Synchronously wait for multiple future and shared_future objects to finish
   and call a function for each of the future objects as soon as it becomes
   ready.]
  [__hpx__ only]]
]

[endsect]

[endsect]

